# This file is a template, and might need editing before it works on your project.
# To contribute improvements to CI/CD templates, please follow the Development guide at:
# https://docs.gitlab.com/ee/development/cicd/templates.html
# This specific template is located at:
# https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Python.gitlab-ci.yml

# Official language image. Look for the different tagged releases at:
# https://hub.docker.com/r/library/python/tags/
image: python:latest

# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

# Pip's cache doesn't store the python packages
# https://pip.pypa.io/en/stable/topics/caching/
#
# If you want to also cache the installed packages, you have to install
# them in a virtualenv and cache it as well.
cache:
  paths:
    - .cache/pip
    - venv/

stages:
  - run
  - deploy_code
  - plan
  - deploy
  - plan_destroy
  - destroy

run:
  stage: run
  before_script:
    - python --version
    - pip install virtualenv
    - virtualenv venv
    - source venv/bin/activate
  script:
    - python setup.py bdist_wheel
    - pip install dist/*
  artifacts:
    paths:
      - dist/*.whl
  environment: sandbox
  tags:
    - sandbox
    - us-east-1
    - docker-readonly

1deploy_code_sandbox:
  stage: deploy_code
  when: manual
  before_script:
    - python --version
    - pip install virtualenv
    - virtualenv venv
    - source venv/bin/activate
  script: 
    - echo "Listing files in root:"
    - ls -l
    - pip install awscli boto3
    - aws s3 cp configs/config.json s3://ds-data-databricks-sandbox/configs/config.json
    - cd dist/
    - echo "Listing files in /dist:"
    - ls -l
    - aws s3 cp DirectSupply-0.0.0-py3-none-any.whl s3://ds-data-databricks-sandbox/artifacts/DirectSupply-0.0.0-py3-none-any.whl
  environment: sandbox
  tags:
    - sandbox
    - us-east-1
    - docker

1plan_sandbox:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: plan
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-sandbox.cloud
    - vault login -method=aws role=deployment-bastion-read-east
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/sandbox)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/sandbox)"
    - cd deploy/account/sandbox
    - terraform init
    - terraform plan
  tags:
    - sandbox
    - us-east-1
    - docker-readonly

1deploy_sandbox:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: deploy
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-sandbox.cloud
    - vault login -method=aws role=deployment-bastion
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/sandbox)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/sandbox)"
    - cd deploy/account/sandbox
    - terraform init
    - terraform apply -auto-approve
  when: manual
  tags:
    - sandbox
    - us-east-1
    - docker

1plan_destroy_sandbox:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: plan_destroy
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-sandbox.cloud
    - vault login -method=aws role=deployment-bastion-read-east
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/sandbox)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/sandbox)"
    - cd deploy/account/sandbox
    - terraform init
    - terraform plan --destroy
  tags:
    - sandbox
    - us-east-1
    - docker-readonly

1destroy_sandbox:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: destroy
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-sandbox.cloud
    - vault login -method=aws role=deployment-bastion
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/sandbox)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/sandbox)"
    - cd deploy/account/sandbox
    - terraform init
    - terraform apply -destroy -auto-approve
  when: manual
  tags:
    - sandbox
    - us-east-1
    - docker


2deploy_code_testing:
  stage: deploy_code
  when: manual
  before_script:
    - python --version
    - pip install virtualenv
    - virtualenv venv
    - source venv/bin/activate
  script:
    - echo "Listing files in root:"
    - ls -l
    - pip install awscli boto3
    - aws s3 cp configs/config.json s3://ds-data-databricks-testing/configs/config.json
    - cd dist/
    - echo "Listing files in /dist:"
    - ls -l
    - aws s3 cp DirectSupply-0.0.0-py3-none-any.whl s3://ds-data-databricks-testing/artifacts/DirectSupply-0.0.0-py3-none-any.whl
  environment: testing
  tags:
    - testing
    - us-east-1
    - docker

2plan_testing:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: plan
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-testing.cloud
    - vault login -method=aws role=deployment-bastion-read-east
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/testing)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/testing)"
    - cd deploy/account/testing
    - terraform init
    - terraform plan
  tags:
    - testing
    - us-east-1
    - docker-readonly

2deploy_testing:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: deploy
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-testing.cloud
    - vault login -method=aws role=deployment-bastion
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/testing)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/testing)"
    - cd deploy/account/testing
    - terraform init
    - terraform apply -auto-approve
  when: manual
  tags:
    - testing
    - us-east-1
    - docker

2plan_destroy_testing:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: plan_destroy
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-testing.cloud
    - vault login -method=aws role=deployment-bastion-read-east
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/testing)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/testing)"
    - cd deploy/account/testing
    - terraform init
    - terraform plan --destroy
  tags:
    - testing
    - us-east-1
    - docker-readonly

2destroy_testing:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: destroy
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply-testing.cloud
    - vault login -method=aws role=deployment-bastion
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/testing)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/testing)"
    - cd deploy/account/testing
    - terraform init
    - terraform apply -destroy -auto-approve
  when: manual
  tags:
    - testing
    - us-east-1
    - docker

3deploy_code_production:
  stage: deploy_code
  when: manual
  only:
  - master
  before_script:
    - python --version
    - pip install virtualenv
    - virtualenv venv
    - source venv/bin/activate
  script:
    - echo "Listing files in root:"
    - ls -l
    - pip install awscli boto3
    - aws s3 cp configs/config.json s3://ds-data-databricks-production/configs/config.json
    - cd dist/
    - echo "Listing files in /dist:"
    - ls -l
    - aws s3 cp DirectSupply-0.0.0-py3-none-any.whl s3://ds-data-databricks-production/artifacts/DirectSupply-0.0.0-py3-none-any.whl
  environment: production
  tags:
    - production
    - us-east-1
    - docker

3plan_production:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: plan
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply.cloud
    - vault login -method=aws role=deployment-bastion-read-east
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/production)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/production)"
    - cd deploy/account/production
    - terraform init
    - terraform plan
  tags:
    - production
    - us-east-1
    - docker-readonly

3deploy_production:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: deploy
  only:
    - master
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply.cloud
    - vault login -method=aws role=deployment-bastion
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/production)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/production)"
    - cd deploy/account/production
    - terraform init
    - terraform apply -auto-approve
  when: manual
  tags:
    - production
    - us-east-1
    - docker

3plan_destroy_production:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: plan_destroy
  when: manual
  only:
    - master
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply.cloud
    - vault login -method=aws role=deployment-bastion-read-east
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/production)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/production)"
    - cd deploy/account/production
    - terraform init
    - terraform plan --destroy
  tags:
    - production
    - us-east-1
    - docker-readonly

3destroy_production:
  before_script:
    - chmod +x runner_setup.sh
    - sh runner_setup.sh
  image:
    name: hashicorp/terraform:1.0.4
    entrypoint: [ "" ]
  stage: destroy
  only:
    - master
  script:
    - export VAULT_ADDR=https://vault.us-east-1.management.directsupply.cloud
    - vault login -method=aws role=deployment-bastion
    - export DATABRICKS_HOST="$(vault kv get -field=host secrets/databricks/production)"
    - export DATABRICKS_TOKEN="$(vault kv get -field=token secrets/databricks/production)"
    - cd deploy/account/production
    - terraform init
    - terraform apply -destroy -auto-approve
  when: manual
  tags:
    - production
    - us-east-1
    - docker